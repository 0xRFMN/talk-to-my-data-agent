{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mypy: disable-error-code=\"import-not-found\"\n",
    "\n",
    "# The notebook should be executed from the project root directory\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"_correct_path\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    sys.path.append(\".\")\n",
    "    print(f\"changed dir to {Path('.').resolve()})\")\n",
    "    _correct_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils.schema import AnalystDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes_20.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Create dataset dictionary\n",
    "dataset = AnalystDataset(\n",
    "    name=os.path.splitext(os.path.basename(dataset_url))[0], data=df.to_dict(\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.schema import RunAnalysisResult\n",
    "\n",
    "with open(\"tests/models/run_analysis_result.json\") as f:\n",
    "    analysis_result = RunAnalysisResult.model_validate_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import cleanse_dataframes\n",
    "\n",
    "cleansed_data = await cleanse_dataframes([dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import suggest_questions\n",
    "\n",
    "suggested_questions = await suggest_questions(cleansed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import get_dictionary\n",
    "\n",
    "dictionary = await get_dictionary([dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import rephrase_message\n",
    "from utils.schema import ChatRequest\n",
    "\n",
    "question = \"What is the relationship between length of stay and readmission?\"\n",
    "chat_response = await rephrase_message(\n",
    "    messages=ChatRequest(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question + \"Please order the chart by readmission rate\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import run_analysis\n",
    "from utils.schema import RunAnalysisRequest\n",
    "\n",
    "analysis_request = RunAnalysisRequest(\n",
    "    data=cleansed_data,\n",
    "    dictionary=dictionary,\n",
    "    question=chat_response,\n",
    ")\n",
    "analysis_result = await run_analysis(analysis_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from utils.api import get_business_analysis, run_charts\n",
    "from utils.schema import (\n",
    "    DataDictionary,\n",
    "    RunBusinessAnalysisRequest,\n",
    "    RunChartsRequest,\n",
    ")\n",
    "\n",
    "# Prepare requests\n",
    "chart_request = RunChartsRequest(\n",
    "    data=analysis_result.data,\n",
    "    question=chat_response,\n",
    ")\n",
    "\n",
    "business_request = RunBusinessAnalysisRequest(\n",
    "    data=analysis_result.data,\n",
    "    dictionary=DataDictionary.from_df(analysis_result.data.to_df()),\n",
    "    question=chat_response,\n",
    ")\n",
    "\n",
    "# Create and start tasks immediately\n",
    "charts_task = asyncio.create_task(run_charts(chart_request))\n",
    "business_task = asyncio.create_task(get_business_analysis(business_request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "\n",
    "from utils.schema import RunBusinessAnalysisResult, RunChartsResult\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "tasks = [charts_task, business_task]\n",
    "\n",
    "# Wait for each task to complete\n",
    "for coro in asyncio.as_completed(tasks):\n",
    "    result = await coro\n",
    "\n",
    "    # Determine which task completed by checking the result structure\n",
    "    if isinstance(result, RunChartsResult) and (result.fig1 or result.fig2):\n",
    "        if result.fig1:\n",
    "            pyo.iplot(result.fig1)\n",
    "        if result.fig2:\n",
    "            pyo.iplot(result.fig2)\n",
    "\n",
    "    elif isinstance(result, RunBusinessAnalysisResult):\n",
    "        print(f\"Bottom Line:\\n{(result.bottom_line or '')}\")\n",
    "\n",
    "        print(f\"Additional Insights:\\n{result.additional_insights}\")\n",
    "\n",
    "        print(\"Follow-up Questions:\")\n",
    "        for q in result.follow_up_questions:\n",
    "            print(f\"- {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tests/models/run_analysis_result.json\", \"w\") as f:\n",
    "    f.write(analysis_result.model_dump_json(indent=4))\n",
    "with open(\"tests/models/run_charts_result.json\", \"w\") as f:\n",
    "    f.write(charts_task.result().model_dump_json(indent=4))\n",
    "with open(\"tests/models/run_business_result.json\", \"w\") as f:\n",
    "    f.write(business_task.result().model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import cleanse_dataframes, get_dictionary\n",
    "from utils.database_helpers import Database\n",
    "\n",
    "db_tables = Database.get_tables()\n",
    "db_datasets = Database.get_data(*db_tables)\n",
    "db_dataset_cleansed = await cleanse_dataframes(db_datasets)\n",
    "db_dictionaries = await get_dictionary(db_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import suggest_questions\n",
    "\n",
    "suggested_questions = await suggest_questions(db_dataset_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.api import run_database_analysis\n",
    "from utils.schema import RunDatabaseAnalysisRequest\n",
    "\n",
    "db_run_analysis = await run_database_analysis(\n",
    "    RunDatabaseAnalysisRequest(\n",
    "        data=db_dataset_cleansed,\n",
    "        dictionary=db_dictionaries,\n",
    "        question=\"How does loan default rate relate to type of loan?\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_run_analysis.data.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_run_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_run_analysis.data.to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}